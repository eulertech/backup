{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Work Assignment\n",
    "1. Load the training and test data\n",
    "2. explore data set for feature types, missing data and etc\n",
    "    * feature selection\n",
    "    * feature correlation matrix\n",
    "3. Build the 1st linear regression model and test its accuracy\n",
    "4. Feature extraction for the loan reason (bag of words, tf-idf, hashing etc)\n",
    "5. Build simple linear regression model without highly-correlated features\n",
    "6. Build second model (regression tree, random forest or polynomial features, SVM etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset and explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import csv,re,os,codecs\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from sklearn import feature_extraction\n",
    "# coding: utf-8\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def money_cleaner(money_str):\n",
    "    #remove dollar sign and coma for money\n",
    "    from re import sub\n",
    "    from decimal import Decimal\n",
    "    return Decimal(sub(r'[^\\d\\-.]','',money_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the metadata into a dictionary\n",
    "with open('Metadata.csv','r') as fh_meta:\n",
    "    metadata = dict(filter(None, csv.reader(fh_meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.89%</td>\n",
       "      <td>54734.0</td>\n",
       "      <td>80364.0</td>\n",
       "      <td>$25,000</td>\n",
       "      <td>$25,000</td>\n",
       "      <td>$19,080</td>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Feb-94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28854.0</td>\n",
       "      <td>52.10%</td>\n",
       "      <td>42.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.71%</td>\n",
       "      <td>55742.0</td>\n",
       "      <td>114426.0</td>\n",
       "      <td>$7,000</td>\n",
       "      <td>$7,000</td>\n",
       "      <td>$673</td>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>CNN</td>\n",
       "      <td>...</td>\n",
       "      <td>Oct-00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33623.0</td>\n",
       "      <td>76.70%</td>\n",
       "      <td>7.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.99%</td>\n",
       "      <td>57167.0</td>\n",
       "      <td>137225.0</td>\n",
       "      <td>$25,000</td>\n",
       "      <td>$25,000</td>\n",
       "      <td>$24,725</td>\n",
       "      <td>36 months</td>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>Web Programmer</td>\n",
       "      <td>...</td>\n",
       "      <td>Jun-00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19878.0</td>\n",
       "      <td>66.30%</td>\n",
       "      <td>17.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.11%</td>\n",
       "      <td>57245.0</td>\n",
       "      <td>138150.0</td>\n",
       "      <td>$1,200</td>\n",
       "      <td>$1,200</td>\n",
       "      <td>$1,200</td>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>city of beaumont texas</td>\n",
       "      <td>...</td>\n",
       "      <td>Jan-85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>40.40%</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.57%</td>\n",
       "      <td>57416.0</td>\n",
       "      <td>139635.0</td>\n",
       "      <td>$10,800</td>\n",
       "      <td>$10,800</td>\n",
       "      <td>$10,692</td>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C3</td>\n",
       "      <td>State Farm Insurance</td>\n",
       "      <td>...</td>\n",
       "      <td>Dec-96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3511.0</td>\n",
       "      <td>25.60%</td>\n",
       "      <td>40.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1       X2        X3       X4       X5       X6          X7 X8  X9  \\\n",
       "0  11.89%  54734.0   80364.0  $25,000  $25,000  $19,080   36 months  B  B4   \n",
       "1  10.71%  55742.0  114426.0   $7,000   $7,000     $673   36 months  B  B5   \n",
       "2  16.99%  57167.0  137225.0  $25,000  $25,000  $24,725   36 months  D  D3   \n",
       "3  13.11%  57245.0  138150.0   $1,200   $1,200   $1,200   36 months  C  C2   \n",
       "4  13.57%  57416.0  139635.0  $10,800  $10,800  $10,692   36 months  C  C3   \n",
       "\n",
       "                      X10 ...     X23  X24   X25 X26   X27  X28      X29  \\\n",
       "0                     NaN ...  Feb-94  0.0   NaN NaN  10.0  0.0  28854.0   \n",
       "1                     CNN ...  Oct-00  0.0   NaN NaN   7.0  0.0  33623.0   \n",
       "2          Web Programmer ...  Jun-00  0.0  41.0 NaN  10.0  0.0  19878.0   \n",
       "3  city of beaumont texas ...  Jan-85  0.0  64.0 NaN   5.0  0.0   2584.0   \n",
       "4    State Farm Insurance ...  Dec-96  1.0  58.0 NaN  14.0  0.0   3511.0   \n",
       "\n",
       "      X30   X31 X32  \n",
       "0  52.10%  42.0   f  \n",
       "1  76.70%   7.0   f  \n",
       "2  66.30%  17.0   f  \n",
       "3  40.40%  31.0   f  \n",
       "4  25.60%  40.0   f  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data for Cleaning & Modeling.csv',sep=',',header=0,low_memory=False,date_parser=[14,22],na_values=[]) \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44409194</td>\n",
       "      <td>47416907</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>Electrician</td>\n",
       "      <td>...</td>\n",
       "      <td>2-Nov</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>19861</td>\n",
       "      <td>64.50%</td>\n",
       "      <td>33</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44017917</td>\n",
       "      <td>47034722</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>A</td>\n",
       "      <td>A1</td>\n",
       "      <td>Executive Assistant</td>\n",
       "      <td>...</td>\n",
       "      <td>Dec-68</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17001</td>\n",
       "      <td>26.20%</td>\n",
       "      <td>36</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44259158</td>\n",
       "      <td>47306871</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>District Sales Leader</td>\n",
       "      <td>...</td>\n",
       "      <td>Oct-98</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>25797</td>\n",
       "      <td>49.90%</td>\n",
       "      <td>33</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44429213</td>\n",
       "      <td>47476932</td>\n",
       "      <td>$10,000</td>\n",
       "      <td>$10,000</td>\n",
       "      <td>$10,000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>pharmacy associate</td>\n",
       "      <td>...</td>\n",
       "      <td>Feb-99</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9586</td>\n",
       "      <td>43.80%</td>\n",
       "      <td>21</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44299188</td>\n",
       "      <td>47346901</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>$24,000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>B</td>\n",
       "      <td>B1</td>\n",
       "      <td>Medical case manager</td>\n",
       "      <td>...</td>\n",
       "      <td>2-Dec</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>31842</td>\n",
       "      <td>41.30%</td>\n",
       "      <td>43</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1        X2        X3       X4       X5       X6          X7 X8  X9  \\\n",
       "0 NaN  44409194  47416907   $6,000   $6,000   $6,000   36 months  C  C5   \n",
       "1 NaN  44017917  47034722  $24,000  $24,000  $24,000   36 months  A  A1   \n",
       "2 NaN  44259158  47306871  $35,000  $35,000  $35,000   36 months  C  C2   \n",
       "3 NaN  44429213  47476932  $10,000  $10,000  $10,000   60 months  D  D1   \n",
       "4 NaN  44299188  47346901  $24,000  $24,000  $24,000   60 months  B  B1   \n",
       "\n",
       "                     X10 ...     X23 X24   X25    X26 X27 X28    X29     X30  \\\n",
       "0            Electrician ...   2-Nov   1  26.0    NaN  18   0  19861  64.50%   \n",
       "1    Executive Assistant ...  Dec-68   1   NaN    NaN  12   0  17001  26.20%   \n",
       "2  District Sales Leader ...  Oct-98   0   NaN    NaN  16   0  25797  49.90%   \n",
       "3     pharmacy associate ...  Feb-99   1   NaN  114.0  13   1   9586  43.80%   \n",
       "4   Medical case manager ...   2-Dec   0  48.0    NaN  27   0  31842  41.30%   \n",
       "\n",
       "  X31 X32  \n",
       "0  33   f  \n",
       "1  36   w  \n",
       "2  33   w  \n",
       "3  21   w  \n",
       "4  43   w  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Holdout for Testing.csv',sep=',',header=0,low_memory=False,date_parser=[14,22],na_values=[])\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#columns to transform and clean up after converting types\n",
    "for n in train.columns:\n",
    "    if (train.dtypes[n] == 'object'):\n",
    "        #print(\"Converting column %s to String Type.\"%n)\n",
    "        train[n] = train[n].astype('str')       \n",
    "#same for test dataset, just in case there are difference\n",
    "for n in test.columns:   \n",
    "    if (test.dtypes[n] == 'object'):\n",
    "        #print(\"Converting column %s to String Type.\"%n)\n",
    "        test[n] = test[n].astype('str')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((400000, 32), (80000, 32), (480000, 32))\n"
     ]
    }
   ],
   "source": [
    "#merge training and test data set for transforming and cleaning\n",
    "train['X1'] = train['X1'].apply(lambda x: float(x.rstrip('%')))\n",
    "all_data = train.append(test)\n",
    "print(train.shape[:],test.shape[:],all_data.shape[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure data merged correctly\n",
    "assert str(all_data.iloc[400001]['X16']) == str(test.iloc[1]['X16']),\"Hey,Someting is wrong after merge at column \" + col\n",
    "assert str(all_data.iloc[400001]['X4']) == str(test.iloc[1]['X4']),\"Hey,Someting is wrong after merge at column \" + col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transforming and cleaning.\n",
    "```#cols_cleanup = ['X1','X4','X5','X6','X7','X11','X15','X23','X30','X19']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data['X30'] = all_data['X30'].apply(lambda x: float(x.rstrip('%')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data['X4'] = all_data['X4'].apply(lambda x:float(x.replace('$','').replace(',','')))\n",
    "all_data['X5'] = all_data['X5'].apply(lambda x:float(x.replace('$','').replace(',','')))\n",
    "all_data['X6'] = all_data['X6'].apply(lambda x:float(x.replace('$','').replace(',','')))\n",
    "all_data['X7'] = all_data['X7'].apply(lambda x:float(x.split()[0]))\n",
    "all_data['X19'] = all_data['X19'].apply(lambda x: float(x[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#special treatment for number of year empoloyed\n",
    "# < 1 year set to zero; >=10 to 10\n",
    "def num_year_employed_strip(string):\n",
    "    num_year_employed = re.findall(\"[-\\d]+\",string)\n",
    "    if(len(num_year_employed) == 0):\n",
    "        return np.nan\n",
    "    elif((string.find('<') == 0) and (len(num_year_employed) >= 1)):\n",
    "        return 0\n",
    "    else:\n",
    "        return float(num_year_employed[0])\n",
    "    \n",
    "all_data['X11'] = all_data['X11'].apply(lambda x: num_year_employed_strip(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def x15_parser(d):\n",
    "        try:\n",
    "            return datetime.strptime(d,'%b-%d')\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return datetime.strptime(d,'%d-%b')\n",
    "        \n",
    "all_data['X15'] = all_data['X15'].apply(lambda d: x15_parser(d))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X23 is more complicated than x15 as it contains day-month and Mon-Year\n",
    "def x23_parser(d):\n",
    "    try:\n",
    "        return datetime.strptime(d,'%b-%y')\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return datetime.strptime(d,'%d-%b')\n",
    "        \n",
    "all_data['X23'] = all_data['X23'].apply(lambda d: x23_parser(d))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check any duplicate borrower and loans\n",
    "assert len(all_data['X2'].unique()) == all_data.shape[0], \"duplicate loans exist\"\n",
    "assert len(all_data['X3'].unique()) == all_data.shape[0], \"duplicate borrowers exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process column X16 with TF-IDF and clustering for loan reasons\n",
    "1. First remove stop words and stem it\n",
    "2. Compute TF-IDF and then compute similarity matrix\n",
    "3. Use K-mean cluster to group the loan reasons\n",
    "4. Assign cluster group to a new loan reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to a lack of personal finance education and exposure to poor financing skills growing up, I was easy prey for credit predators. I am devoted to becoming debt-free and can assure my lenders that I \n"
     ]
    }
   ],
   "source": [
    "documents = all_data['X16'].tolist()\n",
    "print (documents[0][0:200])  # first 20 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stopwords, stemming and tokenizing\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try <a href=\"https://radimrehurek.com/gensim/tut2.html\"> gensim for topic modeling </a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [tokenize_and_stem(document.decode('utf-8')) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x487afd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary = corpora.Dictionary(texts)  #{'we':11,'not':10,'loan',0} token:id\n",
    "#dictionary.save('dict_token.dict')\n",
    "corpora.Dictionary.load('dict_token.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e05ed6c04318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m#[(0,1),(1,1),(2,1)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]   #[(0,1),(1,1),(2,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 5), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('dict_token.txt',corpus) # store to disk, for later use, serialize it one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus],num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on csr_matrix in module scipy.sparse.csr object:\n",
      "\n",
      "class csr_matrix(scipy.sparse.compressed._cs_matrix, scipy.sparse.sputils.IndexMixin)\n",
      " |  Compressed Sparse Row matrix\n",
      " |  \n",
      " |  This can be instantiated in several ways:\n",
      " |      csr_matrix(D)\n",
      " |          with a dense matrix or rank-2 ndarray D\n",
      " |  \n",
      " |      csr_matrix(S)\n",
      " |          with another sparse matrix S (equivalent to S.tocsr())\n",
      " |  \n",
      " |      csr_matrix((M, N), [dtype])\n",
      " |          to construct an empty matrix with shape (M, N)\n",
      " |          dtype is optional, defaulting to dtype='d'.\n",
      " |  \n",
      " |      csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
      " |          where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
      " |          relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
      " |  \n",
      " |      csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
      " |          is the standard CSR representation where the column indices for\n",
      " |          row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
      " |          corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
      " |          If the shape parameter is not supplied, the matrix dimensions\n",
      " |          are inferred from the index arrays.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  dtype : dtype\n",
      " |      Data type of the matrix\n",
      " |  shape : 2-tuple\n",
      " |      Shape of the matrix\n",
      " |  ndim : int\n",
      " |      Number of dimensions (this is always 2)\n",
      " |  nnz\n",
      " |      Number of nonzero elements\n",
      " |  data\n",
      " |      CSR format data array of the matrix\n",
      " |  indices\n",
      " |      CSR format index array of the matrix\n",
      " |  indptr\n",
      " |      CSR format index pointer array of the matrix\n",
      " |  has_sorted_indices\n",
      " |      Whether indices are sorted\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  \n",
      " |  Sparse matrices can be used in arithmetic operations: they support\n",
      " |  addition, subtraction, multiplication, division, and matrix power.\n",
      " |  \n",
      " |  Advantages of the CSR format\n",
      " |    - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
      " |    - efficient row slicing\n",
      " |    - fast matrix vector products\n",
      " |  \n",
      " |  Disadvantages of the CSR format\n",
      " |    - slow column slicing operations (consider CSC)\n",
      " |    - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from scipy.sparse import csr_matrix\n",
      " |  >>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
      " |  array([[0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0]], dtype=int8)\n",
      " |  \n",
      " |  >>> row = np.array([0, 0, 1, 2, 2, 2])\n",
      " |  >>> col = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  >>> indptr = np.array([0, 2, 3, 6])\n",
      " |  >>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  As an example of how to construct a CSR matrix incrementally,\n",
      " |  the following snippet builds a term-document matrix from texts:\n",
      " |  \n",
      " |  >>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
      " |  >>> indptr = [0]\n",
      " |  >>> indices = []\n",
      " |  >>> data = []\n",
      " |  >>> vocabulary = {}\n",
      " |  >>> for d in docs:\n",
      " |  ...     for term in d:\n",
      " |  ...         index = vocabulary.setdefault(term, len(vocabulary))\n",
      " |  ...         indices.append(index)\n",
      " |  ...         data.append(1)\n",
      " |  ...     indptr.append(len(indices))\n",
      " |  ...\n",
      " |  >>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
      " |  array([[2, 1, 0, 0],\n",
      " |         [0, 1, 1, 1]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      csr_matrix\n",
      " |      scipy.sparse.compressed._cs_matrix\n",
      " |      scipy.sparse.data._data_matrix\n",
      " |      scipy.sparse.base.spmatrix\n",
      " |      scipy.sparse.data._minmax_mixin\n",
      " |      scipy.sparse.sputils.IndexMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  getcol(self, i)\n",
      " |      Returns a copy of column i of the matrix, as a (m x 1)\n",
      " |      CSR matrix (column vector).\n",
      " |  \n",
      " |  getrow(self, i)\n",
      " |      Returns a copy of row i of the matrix, as a (1 x n)\n",
      " |      CSR matrix (row vector).\n",
      " |  \n",
      " |  tobsr(self, blocksize=None, copy=True)\n",
      " |  \n",
      " |  tocsc(self)\n",
      " |  \n",
      " |  tocsr(self, copy=False)\n",
      " |  \n",
      " |  tolil(self)\n",
      " |  \n",
      " |  transpose(self, copy=False)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |  \n",
      " |  __init__(self, arg1, shape=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __setitem__(self, index, x)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  check_format(self, full_check=True)\n",
      " |      check whether the matrix format is valid\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      full_check : bool, optional\n",
      " |          If `True`, rigorous check, O(N) operations. Otherwise\n",
      " |          basic check, O(1) operations (default True).\n",
      " |  \n",
      " |  diagonal(self)\n",
      " |      Returns the main diagonal of the matrix\n",
      " |  \n",
      " |  eliminate_zeros(self)\n",
      " |      Remove zero entries from the matrix\n",
      " |      \n",
      " |      This is an *in place* operation\n",
      " |  \n",
      " |  getnnz(self, axis=None)\n",
      " |      Get the count of explicitly-stored values (nonzeros)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None, 0, 1}, optional\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |  \n",
      " |  maximum(self, other)\n",
      " |  \n",
      " |  minimum(self, other)\n",
      " |  \n",
      " |  multiply(self, other)\n",
      " |      Point-wise multiplication by another matrix, vector, or\n",
      " |      scalar.\n",
      " |  \n",
      " |  prune(self)\n",
      " |      Remove empty space after all non-zero elements.\n",
      " |  \n",
      " |  sort_indices(self)\n",
      " |      Sort the indices of this matrix *in place*\n",
      " |  \n",
      " |  sorted_indices(self)\n",
      " |      Return a copy of this matrix with sorted indices\n",
      " |  \n",
      " |  sum(self, axis=None)\n",
      " |      Sum the matrix over the given axis.  If the axis is None, sum\n",
      " |      over both rows and columns, returning a scalar.\n",
      " |  \n",
      " |  sum_duplicates(self)\n",
      " |      Eliminate duplicate matrix entries by adding them together\n",
      " |      \n",
      " |      The is an *in place* operation\n",
      " |  \n",
      " |  toarray(self, order=None, out=None)\n",
      " |      See the docstring for `spmatrix.toarray`.\n",
      " |  \n",
      " |  tocoo(self, copy=True)\n",
      " |      Return a COOrdinate representation of this matrix\n",
      " |      \n",
      " |      When copy=False the index and data arrays are not copied.\n",
      " |  \n",
      " |  todia(self)\n",
      " |  \n",
      " |  todok(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  has_canonical_format\n",
      " |      Determine whether the matrix has sorted indices and no duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the above applies\n",
      " |          - False: otherwise\n",
      " |      \n",
      " |      has_canonical_format implies has_sorted_indices, so if the latter flag\n",
      " |      is False, so will the former be; if the former is found True, the\n",
      " |      latter flag is also set.\n",
      " |  \n",
      " |  has_sorted_indices\n",
      " |      Determine whether the matrix has sorted indices\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the indices of the matrix are in sorted order\n",
      " |          - False: otherwise\n",
      " |  \n",
      " |  nnz\n",
      " |      Get the count of explicitly-stored values (nonzeros)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None, 0, 1}, optional\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  arcsin(self)\n",
      " |      Element-wise arcsin.\n",
      " |      \n",
      " |      See numpy.arcsin for more information.\n",
      " |  \n",
      " |  arcsinh(self)\n",
      " |      Element-wise arcsinh.\n",
      " |      \n",
      " |      See numpy.arcsinh for more information.\n",
      " |  \n",
      " |  arctan(self)\n",
      " |      Element-wise arctan.\n",
      " |      \n",
      " |      See numpy.arctan for more information.\n",
      " |  \n",
      " |  arctanh(self)\n",
      " |      Element-wise arctanh.\n",
      " |      \n",
      " |      See numpy.arctanh for more information.\n",
      " |  \n",
      " |  astype(self, t)\n",
      " |  \n",
      " |  ceil(self)\n",
      " |      Element-wise ceil.\n",
      " |      \n",
      " |      See numpy.ceil for more information.\n",
      " |  \n",
      " |  conj(self)\n",
      " |  \n",
      " |  copy(self)\n",
      " |  \n",
      " |  deg2rad(self)\n",
      " |      Element-wise deg2rad.\n",
      " |      \n",
      " |      See numpy.deg2rad for more information.\n",
      " |  \n",
      " |  expm1(self)\n",
      " |      Element-wise expm1.\n",
      " |      \n",
      " |      See numpy.expm1 for more information.\n",
      " |  \n",
      " |  floor(self)\n",
      " |      Element-wise floor.\n",
      " |      \n",
      " |      See numpy.floor for more information.\n",
      " |  \n",
      " |  log1p(self)\n",
      " |      Element-wise log1p.\n",
      " |      \n",
      " |      See numpy.log1p for more information.\n",
      " |  \n",
      " |  power(self, n, dtype=None)\n",
      " |      This function performs element-wise power.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : n is a scalar\n",
      " |      \n",
      " |      dtype : If dtype is not specified, the current dtype will be preserved.\n",
      " |  \n",
      " |  rad2deg(self)\n",
      " |      Element-wise rad2deg.\n",
      " |      \n",
      " |      See numpy.rad2deg for more information.\n",
      " |  \n",
      " |  rint(self)\n",
      " |      Element-wise rint.\n",
      " |      \n",
      " |      See numpy.rint for more information.\n",
      " |  \n",
      " |  sign(self)\n",
      " |      Element-wise sign.\n",
      " |      \n",
      " |      See numpy.sign for more information.\n",
      " |  \n",
      " |  sin(self)\n",
      " |      Element-wise sin.\n",
      " |      \n",
      " |      See numpy.sin for more information.\n",
      " |  \n",
      " |  sinh(self)\n",
      " |      Element-wise sinh.\n",
      " |      \n",
      " |      See numpy.sinh for more information.\n",
      " |  \n",
      " |  sqrt(self)\n",
      " |      Element-wise sqrt.\n",
      " |      \n",
      " |      See numpy.sqrt for more information.\n",
      " |  \n",
      " |  tan(self)\n",
      " |      Element-wise tan.\n",
      " |      \n",
      " |      See numpy.tan for more information.\n",
      " |  \n",
      " |  tanh(self)\n",
      " |      Element-wise tanh.\n",
      " |      \n",
      " |      See numpy.tanh for more information.\n",
      " |  \n",
      " |  trunc(self)\n",
      " |      Element-wise trunc.\n",
      " |      \n",
      " |      See numpy.trunc for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __div__(self, other)\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __idiv__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      # What should len(sparse) return? For consistency with dense matrices,\n",
      " |      # perhaps it should be the number of rows?  But for some uses the number of\n",
      " |      # non-zeros is more important.  For now, raise an exception!\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |      interpret other and call one of the following\n",
      " |      \n",
      " |      self._mul_scalar()\n",
      " |      self._mul_vector()\n",
      " |      self._mul_multivector()\n",
      " |      self._mul_sparse_matrix()\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __numpy_ufunc__(self, func, method, pos, inputs, **kwargs)\n",
      " |      Method for compatibility with NumPy's ufuncs and dot\n",
      " |      functions.\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __rdiv__(self, other)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  asformat(self, format)\n",
      " |      Return this matrix in a given sparse format\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      format : {string, None}\n",
      " |          desired sparse matrix format\n",
      " |              - None for no format conversion\n",
      " |              - \"csr\" for csr_matrix format\n",
      " |              - \"csc\" for csc_matrix format\n",
      " |              - \"lil\" for lil_matrix format\n",
      " |              - \"dok\" for dok_matrix format and so on\n",
      " |  \n",
      " |  asfptype(self)\n",
      " |      Upcast matrix to a floating point format (if necessary)\n",
      " |  \n",
      " |  conjugate(self)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Ordinary dot product\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> v = np.array([1, 0, -1])\n",
      " |      >>> A.dot(v)\n",
      " |      array([ 1, -3, -1], dtype=int64)\n",
      " |  \n",
      " |  getH(self)\n",
      " |      # Renamed conjtranspose() -> getH() for compatibility with dense matrices\n",
      " |  \n",
      " |  get_shape(self)\n",
      " |  \n",
      " |  getformat(self)\n",
      " |  \n",
      " |  getmaxprint(self)\n",
      " |  \n",
      " |  mean(self, axis=None)\n",
      " |      Average the matrix over the given axis.  If the axis is None,\n",
      " |      average over both rows and columns, returning a scalar.\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      nonzero indices\n",
      " |      \n",
      " |      Returns a tuple of arrays (row,col) containing the indices\n",
      " |      of the non-zero elements of the matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])\n",
      " |      >>> A.nonzero()\n",
      " |      (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))\n",
      " |  \n",
      " |  reshape(self, shape)\n",
      " |  \n",
      " |  set_shape(self, shape)\n",
      " |  \n",
      " |  setdiag(self, values, k=0)\n",
      " |      Set diagonal or off-diagonal elements of the array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : array_like\n",
      " |          New values of the diagonal elements.\n",
      " |      \n",
      " |          Values may have any length.  If the diagonal is longer than values,\n",
      " |          then the remaining diagonal entries will not be set.  If values if\n",
      " |          longer than the diagonal, then the remaining values are ignored.\n",
      " |      \n",
      " |          If a scalar value is given, all of the diagonal is set to it.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Which off-diagonal to set, corresponding to elements a[i,i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |  \n",
      " |  todense(self, order=None, out=None)\n",
      " |      Return a dense matrix representation of this matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Whether to store multi-dimensional data in C (row-major)\n",
      " |          or Fortran (column-major) order in memory. The default\n",
      " |          is 'None', indicating the NumPy default of C-ordered.\n",
      " |          Cannot be specified in conjunction with the `out`\n",
      " |          argument.\n",
      " |      \n",
      " |      out : ndarray, 2-dimensional, optional\n",
      " |          If specified, uses this array (or `numpy.matrix`) as the\n",
      " |          output buffer instead of allocating a new array to\n",
      " |          return. The provided array must have the same shape and\n",
      " |          dtype as the sparse matrix on which you are calling the\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.matrix, 2-dimensional\n",
      " |          A NumPy matrix object with the same shape and containing\n",
      " |          the same data represented by the sparse matrix, with the\n",
      " |          requested memory order. If `out` was passed and was an\n",
      " |          array (rather than a `numpy.matrix`), it will be filled\n",
      " |          with the appropriate values and returned wrapped in a\n",
      " |          `numpy.matrix` object that shares the same memory.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __array_priority__ = 10.1\n",
      " |  \n",
      " |  ndim = 2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._minmax_mixin:\n",
      " |  \n",
      " |  max(self, axis=None)\n",
      " |      Maximum of the elements of this matrix.\n",
      " |      \n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amax : self.dtype\n",
      " |          Maximum element.\n",
      " |  \n",
      " |  min(self, axis=None)\n",
      " |      Minimum of the elements of this matrix.\n",
      " |      \n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amin : self.dtype\n",
      " |          Minimum element.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Streaming - One Document at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in documents:\n",
    "            #Assume there is one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "corpus_memory_friendly = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 41s\n",
      "(480000, 38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, max_features=2000,\n",
    "                                 min_df=0.02, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,2))\n",
    "#try 1000 documents\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(documents) #fit the vectorizer to corpus\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ad', u'ad loan', u'ad pay', u'borrow', u'borrow ad', u'br', u'br borrow', u'br br', u'br/', u'card', u'card debt', u'consolid', u'consolid credit', u'credit', u'credit card', u'current', u'debt', u'help', u'high', u'home', u'job', u'like', u'loan', u'lower', u'make', u'money', u'month', u'need', u'pay', u'pay credit', u'payment', u'rate', u'thank', u'time', u'use', u'want', u'work', u'year']\n"
     ]
    }
   ],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(terms[0:max(tfidf_matrix.shape[1],50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> It is a chanllenge to compute cosine_similarity in memory due to its size, PySpark will help here! </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import pairwise_kernels  # significantly slower than cosine_similarity\n",
    "#%time dist = 1 - pairwise_kernels(tfidf_matrix,metric='cosine',n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#%time dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "#print(dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f5b833df8561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# if memory error, loop to compute cosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#symetric matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if memory error, loop to compute cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "dist = np.empty([tfidf_matrix.shape[0],tfidf_matrix.shape[0]])  #symetric matrix\n",
    "for n in range(tfidf_matrix.shape[0]):\n",
    "    for m in range(n,tfidf_matrix.shape[0]):\n",
    "        dist[n,m] = cosine(tfidf_matrix[m].todense(),tfidf_matrix[m].todense())\n",
    "#fill the other half\n",
    "print('fill the other half')\n",
    "%time dist = np.maximum(dist,dist.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 50s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 20  # 20 different kind of loan reasons should cover almost all \n",
    "km = KMeans(n_clusters = num_clusters)\n",
    "%time km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster\n",
      "cluster 0 words\n",
      "want\n",
      "use\n",
      "help\n",
      "money\n",
      "work\n",
      "thank\n",
      "current\n",
      "time\n",
      "pay\n",
      "make\n",
      "job\n",
      "month\n",
      "ad\n",
      "credit\n",
      "high\n",
      "debt\n",
      "consolid\n",
      "borrow\n",
      "need\n",
      "like\n",
      "()\n",
      "cluster 1 words\n",
      "debt\n",
      "card debt\n",
      "card\n",
      "credit\n",
      "credit card\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "pay\n",
      "loan\n",
      "consolid\n",
      "pay credit\n",
      "payment\n",
      "year\n",
      "high\n",
      "rate\n",
      "ad loan\n",
      "use\n",
      "month\n",
      "()\n",
      "cluster 2 words\n",
      "br\n",
      "ad\n",
      "borrow\n",
      "borrow ad\n",
      "debt\n",
      "want\n",
      "pay\n",
      "help\n",
      "loan\n",
      "use\n",
      "thank\n",
      "credit\n",
      "money\n",
      "work\n",
      "high\n",
      "make\n",
      "payment\n",
      "time\n",
      "month\n",
      "current\n",
      "()\n",
      "cluster 3 words\n",
      "rate\n",
      "credit\n",
      "card\n",
      "br\n",
      "lower\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "credit card\n",
      "pay\n",
      "high\n",
      "loan\n",
      "debt\n",
      "consolid\n",
      "payment\n",
      "want\n",
      "like\n",
      "month\n",
      "year\n",
      "use\n",
      "()\n",
      "cluster 4 words\n",
      "ad pay\n",
      "pay\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "credit\n",
      "high\n",
      "card\n",
      "credit card\n",
      "loan\n",
      "debt\n",
      "rate\n",
      "payment\n",
      "month\n",
      "home\n",
      "br/\n",
      "br borrow\n",
      "br br\n",
      "lower\n",
      "()\n",
      "cluster 5 words\n",
      "like\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "pay\n",
      "credit\n",
      "card\n",
      "credit card\n",
      "consolid\n",
      "loan\n",
      "debt\n",
      "payment\n",
      "high\n",
      "month\n",
      "rate\n",
      "pay credit\n",
      "thank\n",
      "use\n",
      "money\n",
      "()\n",
      "cluster 6 words\n",
      "consolid\n",
      "br\n",
      "borrow\n",
      "borrow ad\n",
      "ad\n",
      "loan\n",
      "credit\n",
      "want\n",
      "payment\n",
      "high\n",
      "pay\n",
      "use\n",
      "month\n",
      "lower\n",
      "rate\n",
      "help\n",
      "thank\n",
      "card\n",
      "money\n",
      "make\n",
      "()\n",
      "cluster 7 words\n",
      "br\n",
      "br br\n",
      "br borrow\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "loan\n",
      "pay\n",
      "debt\n",
      "credit\n",
      "consolid\n",
      "card\n",
      "thank\n",
      "credit card\n",
      "payment\n",
      "year\n",
      "help\n",
      "month\n",
      "use\n",
      "want\n",
      "()\n",
      "cluster 8 words\n",
      "pay\n",
      "credit\n",
      "card\n",
      "credit card\n",
      "pay credit\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "loan\n",
      "want\n",
      "use\n",
      "high\n",
      "ad loan\n",
      "payment\n",
      "month\n",
      "debt\n",
      "money\n",
      "year\n",
      "rate\n",
      "()\n",
      "cluster 9 words\n",
      "loan\n",
      "pay\n",
      "borrow\n",
      "ad\n",
      "br\n",
      "borrow ad\n",
      "use\n",
      "debt\n",
      "payment\n",
      "month\n",
      "thank\n",
      "credit\n",
      "help\n",
      "consolid\n",
      "current\n",
      "time\n",
      "card\n",
      "rate\n",
      "year\n",
      "high\n",
      "()\n",
      "cluster 10 words\n",
      "need\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "br\n",
      "loan\n",
      "pay\n",
      "help\n",
      "money\n",
      "br/\n",
      "work\n",
      "thank\n",
      "debt\n",
      "consolid\n",
      "make\n",
      "year\n",
      "credit\n",
      "time\n",
      "payment\n",
      "month\n",
      "()\n",
      "cluster 11 words\n",
      "payment\n",
      "month\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "loan\n",
      "debt\n",
      "pay\n",
      "make\n",
      "credit\n",
      "consolid\n",
      "card\n",
      "credit card\n",
      "lower\n",
      "time\n",
      "want\n",
      "current\n",
      "rate\n",
      "thank\n",
      "()\n",
      "cluster 12 words\n",
      "br/\n",
      "ad\n",
      "borrow\n",
      "borrow ad\n",
      "loan\n",
      "pay\n",
      "thank\n",
      "credit\n",
      "use\n",
      "debt\n",
      "year\n",
      "job\n",
      "month\n",
      "payment\n",
      "consolid\n",
      "work\n",
      "card\n",
      "time\n",
      "help\n",
      "credit card\n",
      "()\n",
      "cluster 13 words\n",
      "home\n",
      "br\n",
      "ad\n",
      "borrow\n",
      "borrow ad\n",
      "loan\n",
      "need\n",
      "consolid\n",
      "debt\n",
      "use\n",
      "br/\n",
      "make\n",
      "pay\n",
      "year\n",
      "like\n",
      "ad loan\n",
      "want\n",
      "money\n",
      "thank\n",
      "credit\n",
      "()\n",
      "cluster 14 words\n",
      "consolid credit\n",
      "consolid\n",
      "credit\n",
      "card\n",
      "credit card\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "debt\n",
      "card debt\n",
      "loan\n",
      "payment\n",
      "ad loan\n",
      "pay\n",
      "month\n",
      "lower\n",
      "want\n",
      "like\n",
      "rate\n",
      "()\n",
      "cluster 15 words\n",
      "ad loan\n",
      "loan\n",
      "br\n",
      "borrow\n",
      "ad\n",
      "borrow ad\n",
      "consolid\n",
      "debt\n",
      "credit\n",
      "pay\n",
      "use\n",
      "card\n",
      "credit card\n",
      "help\n",
      "high\n",
      "payment\n",
      "rate\n",
      "home\n",
      "month\n",
      "thank\n",
      "()\n",
      "cluster 16 words\n",
      "debt\n",
      "consolid\n",
      "br\n",
      "borrow\n",
      "borrow ad\n",
      "ad\n",
      "loan\n",
      "payment\n",
      "pay\n",
      "lower\n",
      "want\n",
      "month\n",
      "rate\n",
      "year\n",
      "credit\n",
      "br borrow\n",
      "br br\n",
      "like\n",
      "use\n",
      "help\n",
      "()\n",
      "cluster 17 words\n",
      "year\n",
      "borrow\n",
      "work\n",
      "ad\n",
      "pay\n",
      "job\n",
      "borrow ad\n",
      "debt\n",
      "loan\n",
      "time\n",
      "br\n",
      "credit\n",
      "br/\n",
      "use\n",
      "payment\n",
      "help\n",
      "thank\n",
      "current\n",
      "month\n",
      "card\n",
      "()\n",
      "cluster 18 words\n",
      "card\n",
      "credit\n",
      "credit card\n",
      "br\n",
      "borrow\n",
      "borrow ad\n",
      "ad\n",
      "consolid\n",
      "high\n",
      "loan\n",
      "payment\n",
      "pay\n",
      "debt\n",
      "want\n",
      "need\n",
      "use\n",
      "br br\n",
      "br borrow\n",
      "home\n",
      "lower\n",
      "()\n",
      "cluster 19 words\n",
      "ad pay\n",
      "pay credit\n",
      "pay\n",
      "credit\n",
      "card\n",
      "credit card\n",
      "br\n",
      "borrow\n",
      "borrow ad\n",
      "ad\n",
      "card debt\n",
      "debt\n",
      "br borrow\n",
      "br br\n",
      "payment\n",
      "loan\n",
      "rate\n",
      "month\n",
      "home\n",
      "high\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:,::-1]  # sort cluster centers by proximity to centroid\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    #print(\"Cluster %d words: \" % i,end=' ')\n",
    "    print(\"cluster %d words\" % i)\n",
    "    for ind in order_centroids[i,:20]:\n",
    "        #print(\"%s\" % terms[ind], end=' ')\n",
    "        print(''.join(terms[ind]))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data['X16'] = clusters   #assign cluster group code to number of loan reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "print(set(all_data['X16']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data type to categorical \n",
    "``` categorical_cols = ['X8','X9','X10','X12','X14','X17','X20','X32'] #possibly 'X13','X16'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['X8','X9','X10','X12','X14','X17','X18','X20','X32','X16'] \n",
    "for col in categorical_cols:\n",
    "    all_data[col] = all_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign data back to train and test\n",
    "train_processed = all_data.iloc[0:train.shape[0]]\n",
    "test_processed = all_data.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check how many missing data in the training and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top Six data is in column (percentage) \n",
      "('X26', 'Number of months since the last public record.', 0.87211249999999996)\n",
      "('X25', \"Number of months since the borrower's last delinquency.\", 0.54700499999999996)\n",
      "('X13', 'Annual income of borrower', 0.15257000000000001)\n",
      "('X1', 'Interest Rate on the loan', 0.15252499999999999)\n",
      "('X11', 'Number of years employed (0 to 10; 10 = 10 or more)', 0.043845000000000002)\n",
      "('X30', 'Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.', 0.00066750000000000002)\n"
     ]
    }
   ],
   "source": [
    "#percentage of data missing\n",
    "missing_pct_train = train_processed.isnull().sum()/train_processed.shape[0]\n",
    "missing_pct_train.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "print(\"The top Six data is in column (percentage) \" )\n",
    "for n in range(6):\n",
    "    print(missing_pct_train.keys()[n],metadata[missing_pct_train.keys()[n]],missing_pct_train.values[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process missing data in training dataset\n",
    "1. remove record where no interest rate on the loan , about 15% record\n",
    "2. remove record (row) where columns (X2,X3 etc)  less than 0.1%\n",
    "3. Special treatment for X26(num months since last deliquency),X25(num inquiries),X13(annual income),X11 (number year employed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: 338990 rows\n",
      "step 2: 338765 rows\n"
     ]
    }
   ],
   "source": [
    "# remove record with no interest rate in the training data set\n",
    "train_processed_s1 = train_processed[~np.isnan(train_processed['X1'])]\n",
    "print('step 1: %d rows' %train_processed_s1.shape[0])\n",
    "missing_threshold = 0.001\n",
    "# remove record (row) where columns (X2,X3 etc) less than threshold\n",
    "for n in range(len(missing_pct_train)):\n",
    "    if(missing_pct_train.get_value(n) <= missing_threshold ):\n",
    "        key = missing_pct_train.keys()[n]\n",
    "        train_processed_s1.dropna(subset=[key],inplace=True)\n",
    "print('step 2: %d rows' %train_processed_s1.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process X26, X25\n",
    "# X26: num of months since last deliquency, assume NaN is zero if no record\n",
    "train_processed_s1['X26'].fillna(0,inplace=True)\n",
    "# X25: num inquiries, assume NaN is zero if no record\n",
    "train_processed_s1['X25'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b618f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X11: number of year employed (less than 5%), drop it for now\n",
    "plt.hist(train_processed_s1['X11'],10,range=[0,10])\n",
    "plt.title('Number of year employed distriubtion')\n",
    "train_processed_s1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncEAxM7NC/H+axvf/cVDUKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2682048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# X13: Annual Income of borrower (15%), it would be great if there is another model to predict people's income\n",
    "plt.hist(train_processed_s1['X13'][~np.isnan(train_processed_s1['X13'])],100,range = [1000,250000])\n",
    "plt.title('Income distribution')\n",
    "#try fill na with median value\n",
    "train_processed_s1_medianX13 = train_processed_s1.copy(deep=True)\n",
    "train_processed_s1_medianX13['X13'] = train_processed_s1['X13'].fillna(train_processed_s1['X13'].median())\n",
    "#option two, drop it all\n",
    "train_processed_s1_dropX13 = train_processed_s1.copy(deep=True)\n",
    "train_processed_s1_dropX13['X13'].dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert train_processed_s1_dropX13.isnull().sum().sum()==0,\"there are still missing value in the training data set\"\n",
    "assert train_processed_s1_medianX13.isnull().sum().sum()==0,\"there are still missing value in the training data set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process missing data in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_processed = all_data.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing data percentage (total 7) is in column (percentage) \n",
      "('X1', 'Interest Rate on the loan', 1.0)\n",
      "('X15', 'Date loan was issued', 1.0)\n",
      "('X26', 'Number of months since the last public record.', 0.82701250000000004)\n",
      "('X25', \"Number of months since the borrower's last delinquency.\", 0.48380000000000001)\n",
      "('X23', \"Date the borrower's earliest reported credit line was opened\", 0.42521249999999999)\n",
      "('X11', 'Number of years employed (0 to 10; 10 = 10 or more)', 0.054774999999999997)\n",
      "('X30', 'Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.', 0.00037500000000000001)\n"
     ]
    }
   ],
   "source": [
    "missing_test_pct = test_processed.isnull().sum()/test.shape[0]\n",
    "missing_test_pct.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "print(\"The missing data percentage (total 7) is in column (percentage) \" )\n",
    "for n in range(7):\n",
    "    print(missing_test_pct.keys()[n],metadata[missing_test_pct.keys()[n]],missing_test_pct.values[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columns with missing test data\n",
    "``` missing_test_cols = ['X26','X25','X23','X11','X15']```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove record (row) where columns (X30 etc) less than threshold,doesn't apply for test dataset due to score purpose\n",
    "#for n in range(len(missing_test_pct)):\n",
    "#    if(missing_test_pct.get_value(n) <= missing_threshold ):\n",
    "#        key = missing_test_pct.keys()[n]\n",
    "#        test_processed.dropna(subset=[key],inplace=True)\n",
    "#print('step 1: %d rows' %test_processed.shape[0])\n",
    "test_processed['X11'].fillna(0,inplace=True)\n",
    "test_processed['X30'].fillna(0,inplace=True)  # assume 0 if no line utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop column X15 since it 100% missing, for consistence with training data set, just keep it with 0 filled\n",
    "#test_processed.drop('X15',axis=1,inplace=True)\n",
    "test_processed['X15'].fillna(0,inplace=True)  # 'X15' won't be used in model\n",
    "# process X26, X25, X13,X11\n",
    "# X26: num of months since last deliquency, assume NaN is zero if no record\n",
    "test_processed['X26'].fillna(0,inplace=True)\n",
    "# X25: num inquiries, assume NaN is zero if no record\n",
    "test_processed['X25'].fillna(0,inplace=True)\n",
    "# X11 drop it\n",
    "#test_processed.dropna(inplace=True)\n",
    "# X13 \n",
    "#try fill na with median value\n",
    "test_processed_medianX13 = test_processed.copy(deep=True)\n",
    "test_processed_medianX13['X13'] = test_processed_medianX13['X13'].fillna(test_processed['X13'].median())\n",
    "#option two, drop it all\n",
    "#test_prpcessed_dropX13 = test_processed.copy(deep=True)\n",
    "#test_prpcessed_dropX13['X13'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x16f13a20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCzjcDAzs4zDwczMMg4HMzPL/H9sMNqV4DZWwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12579e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check interest rate \n",
    "plt.hist(train_processed_s1['X1'],bins = 20)\n",
    "plt.title('Intrest rate distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge processed train and test data for label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use the dropped training dataset\n",
    "all_data_clean_median = train_processed_s1_dropX13.append(test_processed_medianX13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_cols_2 = ['X8','X9','X10','X12','X14','X17','X18','X20','X32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply label encoding for category dataset\n",
    "from sklearn import preprocessing\n",
    "le  = preprocessing.LabelEncoder()\n",
    "for col in categorical_cols_2:\n",
    "    all_data_clean_median[col] = le.fit_transform(all_data_clean_median[col])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use = all_data_clean_median.iloc[0:train_processed_s1_dropX13.shape[0]]\n",
    "test_use = all_data_clean_median.iloc[train_processed_s1_dropX13.shape[0]::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_use.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore colinearilty between features\n",
    "features_exclude = ['X16','X15','X23','X2','X3']\n",
    "#feature_cols = [col for col in train_use.columns if col not in features_exclude]\n",
    "feature_cols = ['X4','X5','X6','X11','X13','X24','X22','X25','X26','X27','X28','X30','X31']\n",
    "corr = np.corrcoef(train_use[feature_cols],rowvar=0)\n",
    "w, v = np.linalg.eig(corr)        # eigen values & eigen vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X11</th>\n",
       "      <th>X13</th>\n",
       "      <th>X24</th>\n",
       "      <th>X22</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.993923</td>\n",
       "      <td>0.122649</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>-0.002003</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>-0.026649</td>\n",
       "      <td>-0.091352</td>\n",
       "      <td>0.198835</td>\n",
       "      <td>-0.070701</td>\n",
       "      <td>0.117450</td>\n",
       "      <td>0.235782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>0.998242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>0.123190</td>\n",
       "      <td>0.349766</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.090819</td>\n",
       "      <td>0.199798</td>\n",
       "      <td>-0.070085</td>\n",
       "      <td>0.118752</td>\n",
       "      <td>0.235669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>0.993923</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126012</td>\n",
       "      <td>0.347909</td>\n",
       "      <td>-0.003975</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>-0.025036</td>\n",
       "      <td>-0.089271</td>\n",
       "      <td>0.200939</td>\n",
       "      <td>-0.068433</td>\n",
       "      <td>0.121285</td>\n",
       "      <td>0.236241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>0.122649</td>\n",
       "      <td>0.123190</td>\n",
       "      <td>0.126012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>-0.007878</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.117558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>0.350427</td>\n",
       "      <td>0.349766</td>\n",
       "      <td>0.347909</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.059219</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.220052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X24</th>\n",
       "      <td>-0.002003</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>-0.003975</td>\n",
       "      <td>-0.007878</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>0.030407</td>\n",
       "      <td>0.099910</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>-0.096677</td>\n",
       "      <td>0.133277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22</th>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.059219</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054897</td>\n",
       "      <td>-0.024427</td>\n",
       "      <td>0.059226</td>\n",
       "      <td>-0.007483</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>0.130531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X25</th>\n",
       "      <td>-0.026649</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.025036</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>-0.054897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>0.060610</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.115495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X26</th>\n",
       "      <td>-0.091352</td>\n",
       "      <td>-0.090819</td>\n",
       "      <td>-0.089271</td>\n",
       "      <td>0.052224</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>0.030407</td>\n",
       "      <td>-0.024427</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033570</td>\n",
       "      <td>0.670360</td>\n",
       "      <td>-0.042946</td>\n",
       "      <td>-0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X27</th>\n",
       "      <td>0.198835</td>\n",
       "      <td>0.199798</td>\n",
       "      <td>0.200939</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.099910</td>\n",
       "      <td>0.059226</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>-0.033570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025467</td>\n",
       "      <td>-0.116872</td>\n",
       "      <td>0.678517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X28</th>\n",
       "      <td>-0.070701</td>\n",
       "      <td>-0.070085</td>\n",
       "      <td>-0.068433</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>-0.007483</td>\n",
       "      <td>0.060610</td>\n",
       "      <td>0.670360</td>\n",
       "      <td>-0.025467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052891</td>\n",
       "      <td>0.006703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X30</th>\n",
       "      <td>0.117450</td>\n",
       "      <td>0.118752</td>\n",
       "      <td>0.121285</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>-0.096677</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>-0.042946</td>\n",
       "      <td>-0.116872</td>\n",
       "      <td>-0.052891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.086684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X31</th>\n",
       "      <td>0.235782</td>\n",
       "      <td>0.235669</td>\n",
       "      <td>0.236241</td>\n",
       "      <td>0.117558</td>\n",
       "      <td>0.220052</td>\n",
       "      <td>0.133277</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>0.115495</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>-0.086684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X4        X5        X6       X11       X13       X24       X22  \\\n",
       "X4   1.000000  0.998242  0.993923  0.122649  0.350427 -0.002003  0.007060   \n",
       "X5   0.998242  1.000000  0.996040  0.123190  0.349766 -0.002227  0.007699   \n",
       "X6   0.993923  0.996040  1.000000  0.126012  0.347909 -0.003975  0.008655   \n",
       "X11  0.122649  0.123190  0.126012  1.000000  0.071581 -0.007878  0.032481   \n",
       "X13  0.350427  0.349766  0.347909  0.071581  1.000000  0.064222  0.059219   \n",
       "X24 -0.002003 -0.002227 -0.003975 -0.007878  0.064222  1.000000  0.024647   \n",
       "X22  0.007060  0.007699  0.008655  0.032481  0.059219  0.024647  1.000000   \n",
       "X25 -0.026649 -0.025952 -0.025036  0.035731  0.020011  0.034436 -0.054897   \n",
       "X26 -0.091352 -0.090819 -0.089271  0.052224 -0.042332  0.030407 -0.024427   \n",
       "X27  0.198835  0.199798  0.200939  0.045154  0.149543  0.099910  0.059226   \n",
       "X28 -0.070701 -0.070085 -0.068433  0.039499 -0.007936  0.037840 -0.007483   \n",
       "X30  0.117450  0.118752  0.121285  0.046588  0.031573 -0.096677 -0.011034   \n",
       "X31  0.235782  0.235669  0.236241  0.117558  0.220052  0.133277  0.130531   \n",
       "\n",
       "          X25       X26       X27       X28       X30       X31  \n",
       "X4  -0.026649 -0.091352  0.198835 -0.070701  0.117450  0.235782  \n",
       "X5  -0.025952 -0.090819  0.199798 -0.070085  0.118752  0.235669  \n",
       "X6  -0.025036 -0.089271  0.200939 -0.068433  0.121285  0.236241  \n",
       "X11  0.035731  0.052224  0.045154  0.039499  0.046588  0.117558  \n",
       "X13  0.020011 -0.042332  0.149543 -0.007936  0.031573  0.220052  \n",
       "X24  0.034436  0.030407  0.099910  0.037840 -0.096677  0.133277  \n",
       "X22 -0.054897 -0.024427  0.059226 -0.007483 -0.011034  0.130531  \n",
       "X25  1.000000  0.031526  0.026760  0.060610  0.007775  0.115495  \n",
       "X26  0.031526  1.000000 -0.033570  0.670360 -0.042946 -0.024885  \n",
       "X27  0.026760 -0.033570  1.000000 -0.025467 -0.116872  0.678517  \n",
       "X28  0.060610  0.670360 -0.025467  1.000000 -0.052891  0.006703  \n",
       "X30  0.007775 -0.042946 -0.116872 -0.052891  1.000000 -0.086684  \n",
       "X31  0.115495 -0.024885  0.678517  0.006703 -0.086684  1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check colinearity\n",
    "pd.DataFrame(corr,index=feature_cols,columns=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the colinearity of the numerical features, there are strong colinearity between X4,X5,X6; and X26,X28; X27,X31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build Model 1: Linear Regression - only use numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "train_split, crossVal = train_test_split(train_use, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for train model is: 0.253588\n",
      "The R2 score for validation model is 0.254896\n",
      "The RMSE for validation model is 3.782509\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['X4','X5','X6','X11','X13','X24','X21','X22','X25','X26','X27','X28','X30','X31'] #numerical feature first\n",
    "x = train_use[feature_cols]\n",
    "y = train_use['X1']\n",
    "clf = Ridge(alpha = 1.0)\n",
    "clf.fit(x,y)\n",
    "# predict validation\n",
    "x_val = crossVal[feature_cols]\n",
    "y_pred = clf.predict(x_val)\n",
    "print(\"The R2 for train model is: %f\"%clf.score(x,y))\n",
    "print(\"The R2 score for validation model is %f\" %r2_score(crossVal['X1'],y_pred))\n",
    "print(\"The RMSE for validation model is %f\" %mean_squared_error(crossVal['X1'],y_pred)**(1/2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model 1.1- remove colinearilty features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for train model is: 0.238472\n",
      "The R2 score for validation model is 0.242129\n",
      "The RMSE for validation model is 3.814778\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['X4','X11','X13','X24','X22','X21','X25','X26','X27','X30']  # remove X5,X6,X31\n",
    "x = train_use[feature_cols]\n",
    "y = train_use['X1']\n",
    "clf = Ridge(alpha = 1.0)\n",
    "clf.fit(x,y)\n",
    "# predict validation\n",
    "x_val = crossVal[feature_cols]\n",
    "y_pred = clf.predict(x_val)\n",
    "print(\"The R2 for train model is: %f\"%clf.score(x,y))\n",
    "print(\"The R2 score for validation model is %f\" %r2_score(crossVal['X1'],y_pred))\n",
    "print(\"The RMSE for validation model is %f\" %mean_squared_error(crossVal['X1'],y_pred)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54886</th>\n",
       "      <th>54887</th>\n",
       "      <th>54888</th>\n",
       "      <th>54889</th>\n",
       "      <th>54890</th>\n",
       "      <th>54891</th>\n",
       "      <th>54892</th>\n",
       "      <th>54893</th>\n",
       "      <th>54894</th>\n",
       "      <th>54895</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>13.79916</td>\n",
       "      <td>15.009684</td>\n",
       "      <td>11.823187</td>\n",
       "      <td>16.194972</td>\n",
       "      <td>12.496613</td>\n",
       "      <td>13.462928</td>\n",
       "      <td>12.134427</td>\n",
       "      <td>18.312617</td>\n",
       "      <td>16.491955</td>\n",
       "      <td>10.328818</td>\n",
       "      <td>...</td>\n",
       "      <td>15.620492</td>\n",
       "      <td>11.711222</td>\n",
       "      <td>11.622011</td>\n",
       "      <td>9.911512</td>\n",
       "      <td>16.542575</td>\n",
       "      <td>14.035354</td>\n",
       "      <td>15.143918</td>\n",
       "      <td>12.269129</td>\n",
       "      <td>13.238484</td>\n",
       "      <td>13.897741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>12.12000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>9.170000</td>\n",
       "      <td>12.530000</td>\n",
       "      <td>17.570000</td>\n",
       "      <td>10.640000</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>6.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>14.330000</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>16.290000</td>\n",
       "      <td>7.120000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>10.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 54896 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5      \\\n",
       "prediction  13.79916  15.009684  11.823187  16.194972  12.496613  13.462928   \n",
       "actual      12.12000  20.200000   7.620000   9.170000  12.530000  17.570000   \n",
       "\n",
       "                6          7          8          9        ...          54886  \\\n",
       "prediction  12.134427  18.312617  16.491955  10.328818    ...      15.620492   \n",
       "actual      10.640000  15.610000  20.200000   6.030000    ...      24.990000   \n",
       "\n",
       "                54887      54888      54889      54890      54891      54892  \\\n",
       "prediction  11.711222  11.622011   9.911512  16.542575  14.035354  15.143918   \n",
       "actual      10.990000  16.590000  14.330000  16.590000   7.900000  16.290000   \n",
       "\n",
       "                54893      54894      54895  \n",
       "prediction  12.269129  13.238484  13.897741  \n",
       "actual       7.120000  13.040000  10.990000  \n",
       "\n",
       "[2 rows x 54896 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([y_pred,crossVal['X1']]),index=['prediction','actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1.2 - add categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X4', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X32']\n",
      "The R2 for train model is: 0.556391\n",
      "The R2 score for validation model is 0.555898\n",
      "The RMSE for validation model is 2.920204\n"
     ]
    }
   ],
   "source": [
    "features_exclude = ['X1','X2','X3','X5','X6','X15','X16','X23','X31','Load_Reason_Hash']\n",
    "feature_cols = [col for col in train_use.columns if col not in features_exclude]\n",
    "print(feature_cols)\n",
    "#feature_cols = ['X4','X11','X13','X24','X22','X25','X26','X27','X30','X18']  # remove X5,X6,X31\n",
    "\n",
    "x = train_use[feature_cols]\n",
    "y = train_use['X1']\n",
    "clf = Ridge(alpha = 1.0)\n",
    "clf.fit(x,y)\n",
    "# predict validation\n",
    "x_val = crossVal[feature_cols]\n",
    "y_pred = clf.predict(x_val)\n",
    "print(\"The R2 for train model is: %f\"%clf.score(x,y))\n",
    "print(\"The R2 score for validation model is %f\" %r2_score(crossVal['X1'],y_pred))\n",
    "print(\"The RMSE for validation model is %f\" %mean_squared_error(crossVal['X1'],y_pred)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose(np.array([y_pred,crossVal['X1']])),\n",
    "             columns=['Prediction','Actural']).to_csv('cross_metric.csv',sep=',',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply first model on test data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = test_use[feature_cols]\n",
    "test_pred = clf.predict(x)\n",
    "np.savetxt('Results from Liang Kuang-Model I.csv',test_pred, fmt='%8.3f',\n",
    "           delimiter=',',newline='\\n',header='Predicted Interest Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model 2 using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X4', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X32']\n",
      "The RMSE for validation model is 0.516804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "features_exclude = ['X1','X2','X3','X5','X6','X15','X16','X23','X31','Load_Reason_Hash']\n",
    "feature_cols = [col for col in train_use.columns if col not in features_exclude]\n",
    "print(feature_cols)\n",
    "x = train_use[feature_cols]\n",
    "y = train_use['X1']\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=100, min_samples_split=1)\n",
    "regressor.fit(x, y)\n",
    "#predict for cross_validation\n",
    "x_val = crossVal[feature_cols]\n",
    "y_pred = regressor.predict(x_val)\n",
    "print(\"The RMSE for validation model is %f\" %mean_squared_error(crossVal['X1'],y_pred)**(1/2.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = test_use[feature_cols]\n",
    "test_pred = regressor.predict(x)\n",
    "np.savetxt('Results from Liang Kuang-Model II.csv',test_pred, fmt='%8.3f',\n",
    "           delimiter=',',newline='\\n',header='Predicted Interest Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model 3 using SVM for non-linear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM requires scaleing features, otherwise it may stuck on local minimum\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(train_use)  \n",
    "X_train = scaler.transform(train_use)  \n",
    "#apply same transformation to test data\n",
    "X_test = scaler.transform(test_use)  \n",
    "train_split, crossVal = train_test_split(X_train, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "features_exclude = ['X1','X2','X3','X5','X6','X15','X16','X23','X31','Load_Reason_Hash']\n",
    "feature_cols = [col for col in train_use.columns if col not in features_exclude]\n",
    "print(feature_cols)\n",
    "\n",
    "x = train_use[feature_cols]\n",
    "y = train_use['X1']\n",
    "svm_regressor = SVR(kernel='poly',C=1e3,degree=2)\n",
    "svm_regressor.fit(x,y)\n",
    "# predict validation\n",
    "x_val = crossVal[feature_cols]\n",
    "y_pred = svm_regressor.predict(x_val)\n",
    "print(\"The R2 for train model is: %f\"%svm_regressor.score(x,y))\n",
    "print(\"The R2 score for validation model is %f\" %r2_score(crossVal['X1'],y_pred))\n",
    "print(\"The RMSE for validation model is %f\" %mean_squared_error(crossVal['X1'],y_pred)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = test_use[feature_cols]\n",
    "test_pred = svm_regressor.predict(x)\n",
    "np.savetxt('Results from Liang Kuang-Model II.csv',test_pred, fmt='%8.3f',\n",
    "           delimiter=',',newline='\\n',header='Predicted Interest Rate')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
